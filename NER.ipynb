{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82f59d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~/.deeppavlov/downloads/ontonotes/\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov import train_model\n",
    "from deeppavlov.core.commands.utils import parse_config\n",
    "\n",
    "model_config = parse_config('ner_ontonotes_bert_mult')\n",
    "\n",
    "# dataset that the model was trained on\n",
    "print(model_config['dataset_reader']['data_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0a0fb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-15 23:57:40.104 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/v1/ner/ner_ontonotes_bert_mult_torch_crf.tar.gz to C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_bert_mult_torch_crf.tar.gz\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1.39G/1.39G [03:58<00:00, 5.80MB/s]\n",
      "2022-12-16 00:01:39.234 INFO in 'deeppavlov.core.data.utils'['utils'] at line 276: Extracting C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_bert_mult_torch_crf.tar.gz archive into C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\n",
      "2022-12-16 00:02:02.933 INFO in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 66: TorchTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n",
      "2022-12-16 00:02:09.390 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 112: [loading vocabulary from C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\tag.dict]\n",
      "2022-12-16 00:02:09.392 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\tag.dict]\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2022-12-16 00:02:15.945 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 153: Load path C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\model is given.\n",
      "2022-12-16 00:02:15.963 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 160: Load path C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\model.pth.tar exists.\n",
      "2022-12-16 00:02:15.964 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 161: Initializing `TorchTransformersSequenceTagger` from saved.\n",
      "2022-12-16 00:02:15.964 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 168: Loading weights from C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\model.pth.tar.\n",
      "2022-12-16 00:02:49.674 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 102: Model was successfully initialized! Model summary:\n",
      " BertForTokenClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=37, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.67s/it]\n",
      "2022-12-16 00:02:51.357 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 198: Initial best ner_f1 of 19.0476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 2, \"metrics\": {\"ner_f1\": 19.0476, \"ner_token_f1\": 13.7931}, \"time_spent\": \"0:00:02\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  3.22s/it]\n",
      "1it [00:02,  2.26s/it]\n",
      "1it [00:02,  2.22s/it]\n",
      "1it [00:02,  2.24s/it]\n",
      "1it [00:02,  2.21s/it]\n",
      "1it [00:02,  2.23s/it]\n",
      "1it [00:02,  2.22s/it]\n",
      "1it [00:02,  2.25s/it]\n",
      "1it [00:02,  2.32s/it]\n",
      "1it [00:02,  2.22s/it]\n",
      "1it [00:02,  2.32s/it]\n",
      "1it [00:02,  2.42s/it]\n",
      "1it [00:02,  2.43s/it]\n",
      "1it [00:02,  2.43s/it]\n",
      "1it [00:02,  2.46s/it]\n",
      "1it [00:02,  2.40s/it]\n",
      "1it [00:02,  2.59s/it]\n",
      "1it [00:02,  2.63s/it]\n",
      "1it [00:02,  2.67s/it]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.94it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 7, \"metrics\": {\"ner_f1\": 29.0323, \"ner_token_f1\": 45.6376}, \"time_spent\": \"0:00:51\", \"epochs_done\": 19, \"batches_seen\": 20, \"train_examples_seen\": 140, \"loss\": 3.1930559515953063}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  6.86it/s]\u001b[A\n",
      "2022-12-16 00:03:40.376 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 211: Did not improve on the ner_f1 of 19.0476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 2, \"metrics\": {\"ner_f1\": 12.5, \"ner_token_f1\": 8.3333}, \"time_spent\": \"0:00:51\", \"epochs_done\": 19, \"batches_seen\": 20, \"train_examples_seen\": 140, \"impatience\": 1, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  3.25s/it]\n",
      "1it [00:02,  2.65s/it]\n",
      "1it [00:02,  2.46s/it]\n",
      "1it [00:02,  2.44s/it]\n",
      "1it [00:02,  2.42s/it]\n",
      "1it [00:02,  2.47s/it]\n",
      "1it [00:02,  2.44s/it]\n",
      "1it [00:02,  2.42s/it]\n",
      "1it [00:02,  2.44s/it]\n",
      "1it [00:02,  2.47s/it]\n",
      "1it [00:02,  2.43s/it]\n",
      "2022-12-16 00:04:11.469 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 112: [loading vocabulary from C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\tag.dict]\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2022-12-16 00:04:17.811 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 153: Load path C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\model is given.\n",
      "2022-12-16 00:04:17.812 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 160: Load path C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\model.pth.tar exists.\n",
      "2022-12-16 00:04:17.813 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 161: Initializing `TorchTransformersSequenceTagger` from saved.\n",
      "2022-12-16 00:04:17.813 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 168: Loading weights from C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\model.pth.tar.\n",
      "2022-12-16 00:04:36.809 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 102: Model was successfully initialized! Model summary:\n",
      " BertForTokenClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=37, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 2, \"metrics\": {\"ner_f1\": 19.0476, \"ner_token_f1\": 13.7931}, \"time_spent\": \"0:00:01\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"test\": {\"eval_examples_count\": 3, \"metrics\": {\"ner_f1\": 15.0, \"ner_token_f1\": 37.7778}, \"time_spent\": \"0:00:01\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-12-16 00:04:43.984 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 112: [loading vocabulary from C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\tag.dict]\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2022-12-16 00:04:50.431 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 153: Load path C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\model is given.\n",
      "2022-12-16 00:04:50.432 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 160: Load path C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\model.pth.tar exists.\n",
      "2022-12-16 00:04:50.433 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 161: Initializing `TorchTransformersSequenceTagger` from saved.\n",
      "2022-12-16 00:04:50.433 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 168: Loading weights from C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\model.pth.tar.\n",
      "2022-12-16 00:04:52.976 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 102: Model was successfully initialized! Model summary:\n",
      " BertForTokenClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=37, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-16 00:04:52.977 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 210: Saving model to C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\model.pth.tar.\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov import train_model\n",
    "from deeppavlov.core.commands.utils import parse_config\n",
    "\n",
    "model_config = parse_config('ner_ontonotes_bert_mult')\n",
    "\n",
    "model_config['dataset_reader']['data_path'] = '.deeppavlov/ttv'\n",
    "model_config['metadata']['variables']['NER_PATH'] = '.deeppavlov/savemodel'\n",
    "\n",
    "model_config = train_model(model_config, download=True)\n",
    "model_config.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72a28f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Пишу', 'код', 'на', 'питон', '.', 'Знаю', 'Java', '.']],\n",
       " [['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config([\"Пишу код на питон. Знаю Java.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2480acf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-25 02:04:25.666 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/v1/ner/ner_ontonotes_bert_mult_torch_crf.tar.gz to C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_bert_mult_torch_crf.tar.gz\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1.39G/1.39G [03:50<00:00, 6.00MB/s]\n",
      "2022-12-25 02:08:16.858 INFO in 'deeppavlov.core.data.utils'['utils'] at line 276: Extracting C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_bert_mult_torch_crf.tar.gz archive into C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\n",
      "2022-12-25 02:08:31.57 INFO in 'deeppavlov.core.trainers.fit_trainer'['fit_trainer'] at line 66: TorchTrainer got additional init parameters ['pytest_max_batches', 'pytest_batch_size'] that will be ignored:\n",
      "2022-12-25 02:08:36.997 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 112: [loading vocabulary from C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\tag.dict]\n",
      "2022-12-25 02:08:37.336 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\tag.dict]\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2022-12-25 02:08:43.702 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 153: Load path C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\model is given.\n",
      "2022-12-25 02:08:43.703 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 160: Load path C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\model.pth.tar exists.\n",
      "2022-12-25 02:08:43.704 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 161: Initializing `TorchTransformersSequenceTagger` from saved.\n",
      "2022-12-25 02:08:43.704 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 168: Loading weights from C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\model.pth.tar.\n",
      "2022-12-25 02:08:47.675 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 102: Model was successfully initialized! Model summary:\n",
      " BertForTokenClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=37, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]c:\\users\\андрей\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torchcrf\\__init__.py:305: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorCompare.cpp:402.)\n",
      "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n",
      "1it [00:03,  3.05s/it]\n",
      "2022-12-25 02:08:50.758 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 198: Initial best ner_f1 of 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 2, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 0}, \"time_spent\": \"0:00:04\", \"epochs_done\": 0, \"batches_seen\": 0, \"train_examples_seen\": 0, \"impatience\": 0, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [01:02,  3.25s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.49it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 0}, \"time_spent\": \"0:01:10\", \"epochs_done\": 0, \"batches_seen\": 20, \"train_examples_seen\": 200, \"loss\": 0.4620365500450134}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 0}, \"time_spent\": \"0:01:10\", \"epochs_done\": 0, \"batches_seen\": 20, \"train_examples_seen\": 200, \"impatience\": 1, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [02:13,  3.46s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 0}, \"time_spent\": \"0:02:22\", \"epochs_done\": 0, \"batches_seen\": 40, \"train_examples_seen\": 400, \"loss\": 0.2616955805569887}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 0}, \"time_spent\": \"0:02:22\", \"epochs_done\": 0, \"batches_seen\": 40, \"train_examples_seen\": 400, \"impatience\": 2, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [03:28,  4.76s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 8.3333, \"ner_token_f1\": 37.2549}, \"time_spent\": \"0:03:37\", \"epochs_done\": 0, \"batches_seen\": 60, \"train_examples_seen\": 600, \"loss\": 0.24189105592668056}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 0}, \"time_spent\": \"0:03:37\", \"epochs_done\": 0, \"batches_seen\": 60, \"train_examples_seen\": 600, \"impatience\": 3, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [04:34,  3.06s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.77it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 12.5, \"ner_token_f1\": 46.6667}, \"time_spent\": \"0:04:42\", \"epochs_done\": 0, \"batches_seen\": 80, \"train_examples_seen\": 800, \"loss\": 0.17454032627865673}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 0}, \"time_spent\": \"0:04:42\", \"epochs_done\": 0, \"batches_seen\": 80, \"train_examples_seen\": 800, \"impatience\": 4, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99it [05:44,  3.31s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.74it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 0}, \"time_spent\": \"0:05:52\", \"epochs_done\": 0, \"batches_seen\": 100, \"train_examples_seen\": 1000, \"loss\": 0.1491463789716363}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 11.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 0}, \"time_spent\": \"0:05:52\", \"epochs_done\": 0, \"batches_seen\": 100, \"train_examples_seen\": 1000, \"impatience\": 5, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "119it [06:47,  3.08s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 16.0, \"ner_token_f1\": 25.5319}, \"time_spent\": \"0:06:55\", \"epochs_done\": 0, \"batches_seen\": 120, \"train_examples_seen\": 1200, \"loss\": 0.13860125690698624}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 0}, \"time_spent\": \"0:06:55\", \"epochs_done\": 0, \"batches_seen\": 120, \"train_examples_seen\": 1200, \"impatience\": 6, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [07:55,  3.19s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.41it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 66.6667, \"ner_token_f1\": 93.3333}, \"time_spent\": \"0:08:02\", \"epochs_done\": 0, \"batches_seen\": 140, \"train_examples_seen\": 1400, \"loss\": 0.11526377778500319}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 0}, \"time_spent\": \"0:08:02\", \"epochs_done\": 0, \"batches_seen\": 140, \"train_examples_seen\": 1400, \"impatience\": 7, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "159it [09:02,  3.55s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 28.5714, \"ner_token_f1\": 50.0}, \"time_spent\": \"0:09:11\", \"epochs_done\": 0, \"batches_seen\": 160, \"train_examples_seen\": 1600, \"loss\": 0.09430922493338585}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 0}, \"time_spent\": \"0:09:11\", \"epochs_done\": 0, \"batches_seen\": 160, \"train_examples_seen\": 1600, \"impatience\": 8, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "179it [10:08,  3.18s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.95it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 8.6957}, \"time_spent\": \"0:10:15\", \"epochs_done\": 0, \"batches_seen\": 180, \"train_examples_seen\": 1800, \"loss\": 0.08251463435590267}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 0}, \"time_spent\": \"0:10:15\", \"epochs_done\": 0, \"batches_seen\": 180, \"train_examples_seen\": 1800, \"impatience\": 9, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "199it [11:11,  2.94s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 33.3333, \"ner_token_f1\": 77.7778}, \"time_spent\": \"0:11:19\", \"epochs_done\": 0, \"batches_seen\": 200, \"train_examples_seen\": 2000, \"loss\": 0.07313052997924388}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 11.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 0}, \"time_spent\": \"0:11:19\", \"epochs_done\": 0, \"batches_seen\": 200, \"train_examples_seen\": 2000, \"impatience\": 10, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "219it [12:22,  3.40s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 18.1818, \"ner_token_f1\": 61.2245}, \"time_spent\": \"0:12:31\", \"epochs_done\": 0, \"batches_seen\": 220, \"train_examples_seen\": 2200, \"loss\": 0.0891559949144721}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 11.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 0}, \"time_spent\": \"0:12:31\", \"epochs_done\": 0, \"batches_seen\": 220, \"train_examples_seen\": 2200, \"impatience\": 11, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239it [13:30,  3.26s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.36it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 0}, \"time_spent\": \"0:13:39\", \"epochs_done\": 0, \"batches_seen\": 240, \"train_examples_seen\": 2400, \"loss\": 0.10755656603723765}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 15.6708, \"ner_token_f1\": 20.9}, \"time_spent\": \"0:13:39\", \"epochs_done\": 0, \"batches_seen\": 240, \"train_examples_seen\": 2400, \"impatience\": 12, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "259it [14:39,  3.28s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 73.6842, \"ner_token_f1\": 84.7059}, \"time_spent\": \"0:14:47\", \"epochs_done\": 0, \"batches_seen\": 260, \"train_examples_seen\": 2600, \"loss\": 0.08332387036643922}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 28.5714, \"ner_token_f1\": 43.0516}, \"time_spent\": \"0:14:48\", \"epochs_done\": 0, \"batches_seen\": 260, \"train_examples_seen\": 2600, \"impatience\": 13, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "279it [15:39,  2.91s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.04it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 70.0, \"ner_token_f1\": 96.1538}, \"time_spent\": \"0:15:48\", \"epochs_done\": 0, \"batches_seen\": 280, \"train_examples_seen\": 2800, \"loss\": 0.07381405616179108}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 25.5714, \"ner_token_f1\": 39.9412}, \"time_spent\": \"0:15:48\", \"epochs_done\": 0, \"batches_seen\": 280, \"train_examples_seen\": 2800, \"impatience\": 14, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "299it [16:48,  3.64s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.33it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 0}, \"time_spent\": \"0:16:57\", \"epochs_done\": 0, \"batches_seen\": 300, \"train_examples_seen\": 3000, \"loss\": 0.06852987986057997}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 13.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 12.5714, \"ner_token_f1\": 49.9412}, \"time_spent\": \"0:16:57\", \"epochs_done\": 0, \"batches_seen\": 300, \"train_examples_seen\": 3000, \"impatience\": 15, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "319it [17:57,  4.05s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 50.0, \"ner_token_f1\": 81.4815}, \"time_spent\": \"0:18:04\", \"epochs_done\": 0, \"batches_seen\": 320, \"train_examples_seen\": 3200, \"loss\": 0.08275463348254561}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 11.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 22.5714, \"ner_token_f1\": 39.9412}, \"time_spent\": \"0:18:04\", \"epochs_done\": 0, \"batches_seen\": 320, \"train_examples_seen\": 3200, \"impatience\": 16, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "339it [19:00,  3.52s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 53.3333, \"ner_token_f1\": 85.7143}, \"time_spent\": \"0:19:07\", \"epochs_done\": 0, \"batches_seen\": 340, \"train_examples_seen\": 3400, \"loss\": 0.07448654035106302}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 13.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 22.5714, \"ner_token_f1\": 39.9412}, \"time_spent\": \"0:19:07\", \"epochs_done\": 0, \"batches_seen\": 340, \"train_examples_seen\": 3400, \"impatience\": 17, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "359it [20:10,  3.15s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.69it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 30.7692, \"ner_token_f1\": 60.0}, \"time_spent\": \"0:20:17\", \"epochs_done\": 0, \"batches_seen\": 360, \"train_examples_seen\": 3600, \"loss\": 0.06683330370578915}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 22.5714, \"ner_token_f1\": 39.9412}, \"time_spent\": \"0:20:17\", \"epochs_done\": 0, \"batches_seen\": 360, \"train_examples_seen\": 3600, \"impatience\": 18, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "379it [21:20,  3.71s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 28.5714, \"ner_token_f1\": 52.9412}, \"time_spent\": \"0:21:29\", \"epochs_done\": 0, \"batches_seen\": 380, \"train_examples_seen\": 3800, \"loss\": 0.07136162640526891}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 11.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 18.42, \"ner_token_f1\": 59.1830}, \"time_spent\": \"0:21:29\", \"epochs_done\": 0, \"batches_seen\": 380, \"train_examples_seen\": 3800, \"impatience\": 19, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "399it [22:25,  2.92s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.48it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 40.0, \"ner_token_f1\": 66.6667}, \"time_spent\": \"0:22:33\", \"epochs_done\": 0, \"batches_seen\": 400, \"train_examples_seen\": 4000, \"loss\": 0.06279339864850045}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 25.0, \"ner_token_f1\": 53.443}, \"time_spent\": \"0:22:33\", \"epochs_done\": 0, \"batches_seen\": 400, \"train_examples_seen\": 4000, \"impatience\": 20, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "419it [23:30,  3.02s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.35it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 46.1538, \"ner_token_f1\": 75.8621}, \"time_spent\": \"0:23:39\", \"epochs_done\": 0, \"batches_seen\": 420, \"train_examples_seen\": 4200, \"loss\": 0.047885727597167714}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 22.7, \"ner_token_f1\": 41.1030}, \"time_spent\": \"0:23:39\", \"epochs_done\": 0, \"batches_seen\": 420, \"train_examples_seen\": 4200, \"impatience\": 21, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "426it [24:01,  3.38s/it]\n",
      "13it [00:42,  3.45s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:02,  2.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 35.2941, \"ner_token_f1\": 72.2222}, \"time_spent\": \"0:24:54\", \"epochs_done\": 1, \"batches_seen\": 440, \"train_examples_seen\": 4399, \"loss\": 0.06438252863008528}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 38.43, \"ner_token_f1\": 55.1030}, \"time_spent\": \"0:24:54\", \"epochs_done\": 1, \"batches_seen\": 440, \"train_examples_seen\": 4399, \"impatience\": 22, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [01:51,  3.58s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.39it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 42.069, \"ner_token_f1\": 84.058}, \"time_spent\": \"0:26:01\", \"epochs_done\": 1, \"batches_seen\": 460, \"train_examples_seen\": 4599, \"loss\": 0.04922878944780677}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 28.7, \"ner_token_f1\": 61.1030}, \"time_spent\": \"0:26:01\", \"epochs_done\": 1, \"batches_seen\": 460, \"train_examples_seen\": 4599, \"impatience\": 23, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53it [03:01,  4.12s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.26it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 50.0, \"ner_token_f1\": 84.8485}, \"time_spent\": \"0:27:11\", \"epochs_done\": 1, \"batches_seen\": 480, \"train_examples_seen\": 4799, \"loss\": 0.050457585137337446}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 14.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 28.7, \"ner_token_f1\": 61.1030}, \"time_spent\": \"0:27:11\", \"epochs_done\": 1, \"batches_seen\": 480, \"train_examples_seen\": 4799, \"impatience\": 24, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "73it [04:10,  3.28s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 54.5455, \"ner_token_f1\": 67.9245}, \"time_spent\": \"0:28:20\", \"epochs_done\": 1, \"batches_seen\": 500, \"train_examples_seen\": 4999, \"loss\": 0.04505815224256367}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 24.32, \"ner_token_f1\": 45.3045}, \"time_spent\": \"0:28:20\", \"epochs_done\": 1, \"batches_seen\": 500, \"train_examples_seen\": 4999, \"impatience\": 25, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "93it [05:14,  2.91s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.95it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 28.5714, \"ner_token_f1\": 54.0541}, \"time_spent\": \"0:29:23\", \"epochs_done\": 1, \"batches_seen\": 520, \"train_examples_seen\": 5199, \"loss\": 0.056459331698715684}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 64.32, \"ner_token_f1\": 88.3045}, \"time_spent\": \"0:29:23\", \"epochs_done\": 1, \"batches_seen\": 520, \"train_examples_seen\": 5199, \"impatience\": 26, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113it [06:21,  4.01s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.77it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 82.3529, \"ner_token_f1\": 92.1053}, \"time_spent\": \"0:30:32\", \"epochs_done\": 1, \"batches_seen\": 540, \"train_examples_seen\": 5399, \"loss\": 0.0486393703147769}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 44.32, \"ner_token_f1\": 75.3045}, \"time_spent\": \"0:30:32\", \"epochs_done\": 1, \"batches_seen\": 540, \"train_examples_seen\": 5399, \"impatience\": 27, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "133it [07:32,  3.70s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.42it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 80.0, \"ner_token_f1\": 92.3077}, \"time_spent\": \"0:31:44\", \"epochs_done\": 1, \"batches_seen\": 560, \"train_examples_seen\": 5599, \"loss\": 0.05873673856258392}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 34.32, \"ner_token_f1\": 55.3045}, \"time_spent\": \"0:31:44\", \"epochs_done\": 1, \"batches_seen\": 560, \"train_examples_seen\": 5599, \"impatience\": 28, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "153it [08:46,  3.40s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 69.5652, \"ner_token_f1\": 90.6667}, \"time_spent\": \"0:32:57\", \"epochs_done\": 1, \"batches_seen\": 580, \"train_examples_seen\": 5799, \"loss\": 0.04319707707036287}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 44.32, \"ner_token_f1\": 75.3045}, \"time_spent\": \"0:32:58\", \"epochs_done\": 1, \"batches_seen\": 580, \"train_examples_seen\": 5799, \"impatience\": 29, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "173it [09:53,  3.07s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.77it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 66.6667, \"ner_token_f1\": 92.8571}, \"time_spent\": \"0:34:03\", \"epochs_done\": 1, \"batches_seen\": 600, \"train_examples_seen\": 5999, \"loss\": 0.055983391241170466}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 11.94it/s]\n",
      "2022-12-25 02:42:49.950 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 245: ----------Current LR is decreased in 1.5 times----------\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2022-12-25 02:42:56.643 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 153: Load path C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\model is given.\n",
      "2022-12-25 02:42:56.645 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 160: Load path C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\model.pth.tar exists.\n",
      "2022-12-25 02:42:56.645 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 161: Initializing `TorchTransformersSequenceTagger` from saved.\n",
      "2022-12-25 02:42:56.645 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 168: Loading weights from C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\model.pth.tar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 0}, \"time_spent\": \"0:34:03\", \"epochs_done\": 1, \"batches_seen\": 600, \"train_examples_seen\": 5999, \"impatience\": 30, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "193it [11:18,  2.87s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.77it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 0}, \"time_spent\": \"0:35:27\", \"epochs_done\": 1, \"batches_seen\": 620, \"train_examples_seen\": 6199, \"loss\": 0.3983009047806263}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 0}, \"time_spent\": \"0:35:27\", \"epochs_done\": 1, \"batches_seen\": 620, \"train_examples_seen\": 6199, \"impatience\": 31, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "213it [12:22,  2.98s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 0}, \"time_spent\": \"0:36:32\", \"epochs_done\": 1, \"batches_seen\": 640, \"train_examples_seen\": 6399, \"loss\": 0.30432610884308814}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 0}, \"time_spent\": \"0:36:32\", \"epochs_done\": 1, \"batches_seen\": 640, \"train_examples_seen\": 6399, \"impatience\": 32, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "233it [13:29,  3.52s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 0}, \"time_spent\": \"0:37:39\", \"epochs_done\": 1, \"batches_seen\": 660, \"train_examples_seen\": 6599, \"loss\": 0.24032655162736774}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 16.1114, \"ner_token_f1\": 31.8090}, \"time_spent\": \"0:37:39\", \"epochs_done\": 1, \"batches_seen\": 660, \"train_examples_seen\": 6599, \"impatience\": 33, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253it [14:34,  3.16s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 0}, \"time_spent\": \"0:38:44\", \"epochs_done\": 1, \"batches_seen\": 680, \"train_examples_seen\": 6799, \"loss\": 0.28081067334860565}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 26.5714, \"ner_token_f1\": 41.8090}, \"time_spent\": \"0:38:44\", \"epochs_done\": 1, \"batches_seen\": 680, \"train_examples_seen\": 6799, \"impatience\": 34, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "273it [15:43,  3.63s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 10.0134, \"ner_token_f1\": 22.0}, \"time_spent\": \"0:39:54\", \"epochs_done\": 1, \"batches_seen\": 700, \"train_examples_seen\": 6999, \"loss\": 0.19596518222242593}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 46.5714, \"ner_token_f1\": 71.8090}, \"time_spent\": \"0:39:54\", \"epochs_done\": 1, \"batches_seen\": 700, \"train_examples_seen\": 6999, \"impatience\": 35, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "293it [16:52,  3.42s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 15.3846, \"ner_token_f1\": 53.8462}, \"time_spent\": \"0:41:02\", \"epochs_done\": 1, \"batches_seen\": 720, \"train_examples_seen\": 7199, \"loss\": 0.15367168448865415}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 36.5714, \"ner_token_f1\": 71.8090}, \"time_spent\": \"0:41:03\", \"epochs_done\": 1, \"batches_seen\": 720, \"train_examples_seen\": 7199, \"impatience\": 36, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "313it [18:01,  2.95s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.27it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 16.6667, \"ner_token_f1\": 54.1667}, \"time_spent\": \"0:42:11\", \"epochs_done\": 1, \"batches_seen\": 740, \"train_examples_seen\": 7399, \"loss\": 0.15889041014015676}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 36.5714, \"ner_token_f1\": 71.8090}, \"time_spent\": \"0:42:11\", \"epochs_done\": 1, \"batches_seen\": 740, \"train_examples_seen\": 7399, \"impatience\": 37, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "333it [19:02,  2.81s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.33it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 28.5714, \"ner_token_f1\": 61.3636}, \"time_spent\": \"0:43:12\", \"epochs_done\": 1, \"batches_seen\": 760, \"train_examples_seen\": 7599, \"loss\": 0.1431537357158959}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 54.8046, \"ner_token_f1\": 74.2007}, \"time_spent\": \"0:43:12\", \"epochs_done\": 1, \"batches_seen\": 760, \"train_examples_seen\": 7599, \"impatience\": 38, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "353it [20:09,  3.13s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.39it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 31.5789, \"ner_token_f1\": 63.8298}, \"time_spent\": \"0:44:18\", \"epochs_done\": 1, \"batches_seen\": 780, \"train_examples_seen\": 7799, \"loss\": 0.13422037996351718}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 54.8046, \"ner_token_f1\": 74.2007}, \"time_spent\": \"0:44:18\", \"epochs_done\": 1, \"batches_seen\": 780, \"train_examples_seen\": 7799, \"impatience\": 39, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "373it [21:18,  3.41s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 13.7931, \"ner_token_f1\": 58.3333}, \"time_spent\": \"0:45:27\", \"epochs_done\": 1, \"batches_seen\": 800, \"train_examples_seen\": 7999, \"loss\": 0.11051532160490751}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 54.8046, \"ner_token_f1\": 74.2007}, \"time_spent\": \"0:45:27\", \"epochs_done\": 1, \"batches_seen\": 800, \"train_examples_seen\": 7999, \"impatience\": 40, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "393it [22:23,  3.59s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 31.5789, \"ner_token_f1\": 59.4595}, \"time_spent\": \"0:46:33\", \"epochs_done\": 1, \"batches_seen\": 820, \"train_examples_seen\": 8199, \"loss\": 0.1164777263533324}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 54.8046, \"ner_token_f1\": 74.2007}, \"time_spent\": \"0:46:33\", \"epochs_done\": 1, \"batches_seen\": 820, \"train_examples_seen\": 8199, \"impatience\": 41, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "413it [23:26,  3.12s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.28it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 52.1739, \"ner_token_f1\": 83.9506}, \"time_spent\": \"0:47:36\", \"epochs_done\": 1, \"batches_seen\": 840, \"train_examples_seen\": 8399, \"loss\": 0.10437807943671942}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 41.3043, \"ner_token_f1\": 54.2557}, \"time_spent\": \"0:47:36\", \"epochs_done\": 1, \"batches_seen\": 840, \"train_examples_seen\": 8399, \"impatience\": 42, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "426it [24:11,  3.41s/it]\n",
      "7it [00:24,  3.76s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.32it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 15.3846, \"ner_token_f1\": 51.8519}, \"time_spent\": \"0:48:46\", \"epochs_done\": 2, \"batches_seen\": 860, \"train_examples_seen\": 8598, \"loss\": 0.10964005813002586}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 61.0043, \"ner_token_f1\": 84.2557}, \"time_spent\": \"0:48:46\", \"epochs_done\": 2, \"batches_seen\": 860, \"train_examples_seen\": 8598, \"impatience\": 43, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [01:31,  3.05s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 30.0, \"ner_token_f1\": 75.7576}, \"time_spent\": \"0:49:52\", \"epochs_done\": 2, \"batches_seen\": 880, \"train_examples_seen\": 8798, \"loss\": 0.10818021576851607}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 41.3043, \"ner_token_f1\": 54.2557}, \"time_spent\": \"0:49:52\", \"epochs_done\": 2, \"batches_seen\": 880, \"train_examples_seen\": 8798, \"impatience\": 44, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47it [02:33,  2.76s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.39it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 0}, \"time_spent\": \"0:50:54\", \"epochs_done\": 2, \"batches_seen\": 900, \"train_examples_seen\": 8998, \"loss\": 0.10538342241197825}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 41.3043, \"ner_token_f1\": 54.2557}, \"time_spent\": \"0:50:54\", \"epochs_done\": 2, \"batches_seen\": 900, \"train_examples_seen\": 8998, \"impatience\": 45, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "67it [03:38,  3.28s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.00s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 60.0, \"ner_token_f1\": 78.2609}, \"time_spent\": \"0:51:59\", \"epochs_done\": 2, \"batches_seen\": 920, \"train_examples_seen\": 9198, \"loss\": 0.08310886565595865}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 61.3043, \"ner_token_f1\": 54.2557}, \"time_spent\": \"0:51:59\", \"epochs_done\": 2, \"batches_seen\": 920, \"train_examples_seen\": 9198, \"impatience\": 46, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "87it [04:43,  3.33s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 32.5, \"ner_token_f1\": 28.5714}, \"time_spent\": \"0:53:05\", \"epochs_done\": 2, \"batches_seen\": 940, \"train_examples_seen\": 9398, \"loss\": 0.0806904044933617}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 41.3043, \"ner_token_f1\": 54.2557}, \"time_spent\": \"0:53:05\", \"epochs_done\": 2, \"batches_seen\": 940, \"train_examples_seen\": 9398, \"impatience\": 47, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "107it [05:54,  3.76s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:02,  2.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 34.2857, \"ner_token_f1\": 41.8605}, \"time_spent\": \"0:54:18\", \"epochs_done\": 2, \"batches_seen\": 960, \"train_examples_seen\": 9598, \"loss\": 0.06359302019700408}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 55.5089, \"ner_token_f1\": 64.2857}, \"time_spent\": \"0:54:18\", \"epochs_done\": 2, \"batches_seen\": 960, \"train_examples_seen\": 9598, \"impatience\": 48, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127it [07:04,  3.46s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.52it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 42.8571, \"ner_token_f1\": 80.0}, \"time_spent\": \"0:55:25\", \"epochs_done\": 2, \"batches_seen\": 980, \"train_examples_seen\": 9798, \"loss\": 0.08474443834275007}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 61.5789, \"ner_token_f1\": 54.2857}, \"time_spent\": \"0:55:25\", \"epochs_done\": 2, \"batches_seen\": 980, \"train_examples_seen\": 9798, \"impatience\": 49, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "147it [08:04,  3.01s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.06it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 31.5789, \"ner_token_f1\": 54.2857}, \"time_spent\": \"0:56:27\", \"epochs_done\": 2, \"batches_seen\": 1000, \"train_examples_seen\": 9998, \"loss\": 0.08122442928142845}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 2, \"metrics\": {\"ner_f1\": 0, \"ner_token_f1\": 0}, \"time_spent\": \"0:56:27\", \"epochs_done\": 2, \"batches_seen\": 1000, \"train_examples_seen\": 9998, \"impatience\": 50, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167it [09:14,  3.37s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 40.0, \"ner_token_f1\": 55.2632}, \"time_spent\": \"0:57:36\", \"epochs_done\": 2, \"batches_seen\": 1020, \"train_examples_seen\": 10198, \"loss\": 0.07537950249388814}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 53.5294, \"ner_token_f1\": 40.4333}, \"time_spent\": \"0:57:36\", \"epochs_done\": 2, \"batches_seen\": 1020, \"train_examples_seen\": 10198, \"impatience\": 51, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "187it [10:20,  3.07s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 52.2222, \"ner_token_f1\": 72.0}, \"time_spent\": \"0:58:42\", \"epochs_done\": 2, \"batches_seen\": 1040, \"train_examples_seen\": 10398, \"loss\": 0.06058294968679547}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 43.5294, \"ner_token_f1\": 63.4783}, \"time_spent\": \"0:58:42\", \"epochs_done\": 2, \"batches_seen\": 1040, \"train_examples_seen\": 10398, \"impatience\": 52, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "207it [11:29,  3.55s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.74it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 80.0, \"ner_token_f1\": 89.7959}, \"time_spent\": \"0:59:50\", \"epochs_done\": 2, \"batches_seen\": 1060, \"train_examples_seen\": 10598, \"loss\": 0.09758922718465328}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 43.5294, \"ner_token_f1\": 63.4783}, \"time_spent\": \"0:59:50\", \"epochs_done\": 2, \"batches_seen\": 1060, \"train_examples_seen\": 10598, \"impatience\": 53, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "227it [12:34,  3.48s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.46it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 40.0, \"ner_token_f1\": 66.6667}, \"time_spent\": \"1:00:56\", \"epochs_done\": 2, \"batches_seen\": 1080, \"train_examples_seen\": 10798, \"loss\": 0.06858109482564032}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 43.5294, \"ner_token_f1\": 63.4783}, \"time_spent\": \"1:00:56\", \"epochs_done\": 2, \"batches_seen\": 1080, \"train_examples_seen\": 10798, \"impatience\": 54, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "247it [13:44,  3.81s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 33.5294, \"ner_token_f1\": 43.4783}, \"time_spent\": \"1:02:07\", \"epochs_done\": 2, \"batches_seen\": 1100, \"train_examples_seen\": 10998, \"loss\": 0.05082009141333401}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 44.1403, \"ner_token_f1\": 93.30}, \"time_spent\": \"1:02:07\", \"epochs_done\": 2, \"batches_seen\": 1100, \"train_examples_seen\": 10998, \"impatience\": 55, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "267it [14:54,  3.51s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 61.5385, \"ner_token_f1\": 88.5246}, \"time_spent\": \"1:03:15\", \"epochs_done\": 2, \"batches_seen\": 1120, \"train_examples_seen\": 11198, \"loss\": 0.0575283148791641}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 54.1403, \"ner_token_f1\": 77.3226}, \"time_spent\": \"1:03:16\", \"epochs_done\": 2, \"batches_seen\": 1120, \"train_examples_seen\": 11198, \"impatience\": 56, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "287it [16:05,  3.59s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.73it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 70.5882, \"ner_token_f1\": 91.1765}, \"time_spent\": \"1:04:27\", \"epochs_done\": 2, \"batches_seen\": 1140, \"train_examples_seen\": 11398, \"loss\": 0.07944397563114762}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 16.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 64.1403, \"ner_token_f1\": 77.3226}, \"time_spent\": \"1:04:27\", \"epochs_done\": 2, \"batches_seen\": 1140, \"train_examples_seen\": 11398, \"impatience\": 57, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "307it [17:11,  3.47s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  2.35it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 20.0, \"ner_token_f1\": 54.5455}, \"time_spent\": \"1:05:32\", \"epochs_done\": 2, \"batches_seen\": 1160, \"train_examples_seen\": 11598, \"loss\": 0.06349178319796919}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 54.1403, \"ner_token_f1\": 87.3226}, \"time_spent\": \"1:05:32\", \"epochs_done\": 2, \"batches_seen\": 1160, \"train_examples_seen\": 11598, \"impatience\": 58, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "327it [18:19,  3.61s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.88it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 54.5455, \"ner_token_f1\": 78.2609}, \"time_spent\": \"1:06:41\", \"epochs_done\": 2, \"batches_seen\": 1180, \"train_examples_seen\": 11798, \"loss\": 0.05964709171094}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 54.1403, \"ner_token_f1\": 87.3226}, \"time_spent\": \"1:06:41\", \"epochs_done\": 2, \"batches_seen\": 1180, \"train_examples_seen\": 11798, \"impatience\": 59, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "347it [19:27,  3.25s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 57.1429, \"ner_token_f1\": 72.7273}, \"time_spent\": \"1:07:49\", \"epochs_done\": 2, \"batches_seen\": 1200, \"train_examples_seen\": 11998, \"loss\": 0.0612882741028443}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 54.1403, \"ner_token_f1\": 87.3226}, \"time_spent\": \"1:07:49\", \"epochs_done\": 2, \"batches_seen\": 1200, \"train_examples_seen\": 11998, \"impatience\": 60, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "367it [20:39,  3.60s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 45.0, \"ner_token_f1\": 73.3333}, \"time_spent\": \"1:09:01\", \"epochs_done\": 2, \"batches_seen\": 1220, \"train_examples_seen\": 12198, \"loss\": 0.0696415654849261}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 54.1403, \"ner_token_f1\": 87.3226}, \"time_spent\": \"1:09:01\", \"epochs_done\": 2, \"batches_seen\": 1220, \"train_examples_seen\": 12198, \"impatience\": 61, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [21:49,  3.47s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.52it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 40.0, \"ner_token_f1\": 61.9048}, \"time_spent\": \"1:10:09\", \"epochs_done\": 2, \"batches_seen\": 1240, \"train_examples_seen\": 12398, \"loss\": 0.06405508555471898}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 54.1403, \"ner_token_f1\": 87.3226}, \"time_spent\": \"1:10:10\", \"epochs_done\": 2, \"batches_seen\": 1240, \"train_examples_seen\": 12398, \"impatience\": 62, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "407it [23:01,  3.33s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 58.3333, \"ner_token_f1\": 88.4211}, \"time_spent\": \"1:11:22\", \"epochs_done\": 2, \"batches_seen\": 1260, \"train_examples_seen\": 12598, \"loss\": 0.049224465852603316}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 54.1403, \"ner_token_f1\": 87.3226}, \"time_spent\": \"1:11:23\", \"epochs_done\": 2, \"batches_seen\": 1260, \"train_examples_seen\": 12598, \"impatience\": 63, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "426it [24:09,  3.40s/it]\n",
      "1it [00:03,  3.59s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.60it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 88.8889, \"ner_token_f1\": 96.5517}, \"time_spent\": \"1:12:34\", \"epochs_done\": 3, \"batches_seen\": 1280, \"train_examples_seen\": 12797, \"loss\": 0.05638245581649244}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 67.1429, \"ner_token_f1\": 80.3226}, \"time_spent\": \"1:12:34\", \"epochs_done\": 3, \"batches_seen\": 1280, \"train_examples_seen\": 12797, \"impatience\": 64, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [01:08,  3.25s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 61.5385, \"ner_token_f1\": 91.7647}, \"time_spent\": \"1:13:40\", \"epochs_done\": 3, \"batches_seen\": 1300, \"train_examples_seen\": 12997, \"loss\": 0.06068721408955753}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 67.1429, \"ner_token_f1\": 80.3226}, \"time_spent\": \"1:13:40\", \"epochs_done\": 3, \"batches_seen\": 1300, \"train_examples_seen\": 12997, \"impatience\": 65, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [02:15,  3.58s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.39it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 50.0, \"ner_token_f1\": 88.8889}, \"time_spent\": \"1:14:47\", \"epochs_done\": 3, \"batches_seen\": 1320, \"train_examples_seen\": 13197, \"loss\": 0.05766812819056213}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 77.1429, \"ner_token_f1\": 80.3226}, \"time_spent\": \"1:14:47\", \"epochs_done\": 3, \"batches_seen\": 1320, \"train_examples_seen\": 13197, \"impatience\": 66, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61it [03:18,  3.10s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"1:15:48\", \"epochs_done\": 3, \"batches_seen\": 1340, \"train_examples_seen\": 13397, \"loss\": 0.07883111429400742}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 67.1429, \"ner_token_f1\": 80.3226}, \"time_spent\": \"1:15:49\", \"epochs_done\": 3, \"batches_seen\": 1340, \"train_examples_seen\": 13397, \"impatience\": 67, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [04:22,  3.52s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.36it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 57.1429, \"ner_token_f1\": 70.9677}, \"time_spent\": \"1:16:53\", \"epochs_done\": 3, \"batches_seen\": 1360, \"train_examples_seen\": 13597, \"loss\": 0.03452086579054594}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 67.1429, \"ner_token_f1\": 80.3226}, \"time_spent\": \"1:16:53\", \"epochs_done\": 3, \"batches_seen\": 1360, \"train_examples_seen\": 13597, \"impatience\": 68, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [05:32,  3.24s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 66.6667, \"ner_token_f1\": 84.2105}, \"time_spent\": \"1:18:03\", \"epochs_done\": 3, \"batches_seen\": 1380, \"train_examples_seen\": 13797, \"loss\": 0.05084949973970652}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 15.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 67.1429, \"ner_token_f1\": 80.3226}, \"time_spent\": \"1:18:03\", \"epochs_done\": 3, \"batches_seen\": 1380, \"train_examples_seen\": 13797, \"impatience\": 69, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "121it [06:36,  3.05s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.09it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 80.0, \"ner_token_f1\": 94.1176}, \"time_spent\": \"1:19:08\", \"epochs_done\": 3, \"batches_seen\": 1400, \"train_examples_seen\": 13997, \"loss\": 0.05536320691462606}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 67.1429, \"ner_token_f1\": 80.3226}, \"time_spent\": \"1:19:08\", \"epochs_done\": 3, \"batches_seen\": 1400, \"train_examples_seen\": 13997, \"impatience\": 70, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "141it [07:51,  4.21s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  2.00it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {{\"ner_f1\": 77.6420, \"ner_token_f1\": 87.9226}, \"time_spent\": \"1:20:22\", \"epochs_done\": 3, \"batches_seen\": 1420, \"train_examples_seen\": 14197, \"loss\": 0.05153839928098023}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 66.6667, \"ner_token_f1\": 75.0}, \"time_spent\": \"1:20:22\", \"epochs_done\": 3, \"batches_seen\": 1420, \"train_examples_seen\": 14197, \"impatience\": 71, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "161it [09:03,  3.50s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.28it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 57.1429, \"ner_token_f1\": 80.3226}, \"time_spent\": \"1:21:34\", \"epochs_done\": 3, \"batches_seen\": 1440, \"train_examples_seen\": 14397, \"loss\": 0.03368901116773486}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 66.6667, \"ner_token_f1\": 75.0}, \"time_spent\": \"1:21:34\", \"epochs_done\": 3, \"batches_seen\": 1440, \"train_examples_seen\": 14397, \"impatience\": 72, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "181it [10:11,  3.38s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.72it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 54.4444, \"ner_token_f1\": 44.4444}, \"time_spent\": \"1:22:42\", \"epochs_done\": 3, \"batches_seen\": 1460, \"train_examples_seen\": 14597, \"loss\": 0.04239204821642488}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 14.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 76.0, \"ner_token_f1\": 79.0104}, \"time_spent\": \"1:22:42\", \"epochs_done\": 3, \"batches_seen\": 1460, \"train_examples_seen\": 14597, \"impatience\": 73, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [11:12,  2.90s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.85it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 42.1053, \"ner_token_f1\": 68.1818}, \"time_spent\": \"1:23:44\", \"epochs_done\": 3, \"batches_seen\": 1480, \"train_examples_seen\": 14797, \"loss\": 0.05037716231308877}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 66.6667, \"ner_token_f1\": 75.0}, \"time_spent\": \"1:23:44\", \"epochs_done\": 3, \"batches_seen\": 1480, \"train_examples_seen\": 14797, \"impatience\": 74, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "221it [12:23,  3.50s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"1:24:55\", \"epochs_done\": 3, \"batches_seen\": 1500, \"train_examples_seen\": 14997, \"loss\": 0.04164597962517291}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 66.6667, \"ner_token_f1\": 75.0}, \"time_spent\": \"1:24:55\", \"epochs_done\": 3, \"batches_seen\": 1500, \"train_examples_seen\": 14997, \"impatience\": 75, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "241it [13:37,  3.49s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 66.6667, \"ner_token_f1\": 75.0}, \"time_spent\": \"1:26:09\", \"epochs_done\": 3, \"batches_seen\": 1520, \"train_examples_seen\": 15197, \"loss\": 0.04997178697958589}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 66.6667, \"ner_token_f1\": 75.0}, \"time_spent\": \"1:26:09\", \"epochs_done\": 3, \"batches_seen\": 1520, \"train_examples_seen\": 15197, \"impatience\": 76, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "261it [14:48,  3.05s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.61it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 54.5455, \"ner_token_f1\": 80.597}, \"time_spent\": \"1:27:19\", \"epochs_done\": 3, \"batches_seen\": 1540, \"train_examples_seen\": 15397, \"loss\": 0.039830197929404676}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 77.0100, \"ner_token_f1\": 69.0}, \"time_spent\": \"1:27:20\", \"epochs_done\": 3, \"batches_seen\": 1540, \"train_examples_seen\": 15397, \"impatience\": 77, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "281it [15:56,  3.07s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.09it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 58.8235, \"ner_token_f1\": 80.8511}, \"time_spent\": \"1:28:27\", \"epochs_done\": 3, \"batches_seen\": 1560, \"train_examples_seen\": 15597, \"loss\": 0.046957040578126906}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 72.123, \"ner_token_f1\": 80.1343}, \"time_spent\": \"1:28:27\", \"epochs_done\": 3, \"batches_seen\": 1560, \"train_examples_seen\": 15597, \"impatience\": 78, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [17:08,  3.50s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 94.1176, \"ner_token_f1\": 98.4127}, \"time_spent\": \"1:29:39\", \"epochs_done\": 3, \"batches_seen\": 1580, \"train_examples_seen\": 15797, \"loss\": 0.04806968020275235}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 70.0, \"ner_token_f1\": 60.0}, \"time_spent\": \"1:29:40\", \"epochs_done\": 3, \"batches_seen\": 1580, \"train_examples_seen\": 15797, \"impatience\": 79, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "321it [18:12,  3.40s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 88.8889, \"ner_token_f1\": 93.3333}, \"time_spent\": \"1:30:44\", \"epochs_done\": 3, \"batches_seen\": 1600, \"train_examples_seen\": 15997, \"loss\": 0.0522687700111419}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 70.0, \"ner_token_f1\": 60.0}, \"time_spent\": \"1:30:44\", \"epochs_done\": 3, \"batches_seen\": 1600, \"train_examples_seen\": 15997, \"impatience\": 80, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "341it [19:29,  3.43s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 88.8889, \"ner_token_f1\": 95.2381}, \"time_spent\": \"1:32:01\", \"epochs_done\": 3, \"batches_seen\": 1620, \"train_examples_seen\": 16197, \"loss\": 0.043805754475761204}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 59.85, \"ner_token_f1\": 88.0800}, \"time_spent\": \"1:32:01\", \"epochs_done\": 3, \"batches_seen\": 1620, \"train_examples_seen\": 16197, \"impatience\": 81, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "361it [20:45,  3.47s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 52.8571, \"ner_token_f1\": 91.3043}, \"time_spent\": \"1:33:17\", \"epochs_done\": 3, \"batches_seen\": 1640, \"train_examples_seen\": 16397, \"loss\": 0.04116806022357196}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 60.0100, \"ner_token_f1\": 73.0}, \"time_spent\": \"1:33:17\", \"epochs_done\": 3, \"batches_seen\": 1640, \"train_examples_seen\": 16397, \"impatience\": 82, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "381it [21:51,  3.40s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 62.5, \"ner_token_f1\": 90.9091}, \"time_spent\": \"1:34:23\", \"epochs_done\": 3, \"batches_seen\": 1660, \"train_examples_seen\": 16597, \"loss\": 0.06274947975762188}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 72.0, \"ner_token_f1\": 64.0}, \"time_spent\": \"1:34:23\", \"epochs_done\": 3, \"batches_seen\": 1660, \"train_examples_seen\": 16597, \"impatience\": 83, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [22:55,  2.94s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.78it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 75.0, \"ner_token_f1\": 91.4286}, \"time_spent\": \"1:35:25\", \"epochs_done\": 3, \"batches_seen\": 1680, \"train_examples_seen\": 16797, \"loss\": 0.046291690226644276}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 58.7737, \"ner_token_f1\": 66.70}, \"time_spent\": \"1:35:26\", \"epochs_done\": 3, \"batches_seen\": 1680, \"train_examples_seen\": 16797, \"impatience\": 84, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "421it [24:00,  3.34s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 70.5882, \"ner_token_f1\": 94.2529}, \"time_spent\": \"1:36:31\", \"epochs_done\": 3, \"batches_seen\": 1700, \"train_examples_seen\": 16997, \"loss\": 0.03902067542367149}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 62.0453, \"ner_token_f1\": 69.1834}, \"time_spent\": \"1:36:31\", \"epochs_done\": 3, \"batches_seen\": 1700, \"train_examples_seen\": 16997, \"impatience\": 85, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "426it [24:19,  3.43s/it]\n",
      "15it [00:49,  3.31s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.28it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 57.1429, \"ner_token_f1\": 86.6667}, \"time_spent\": \"1:37:41\", \"epochs_done\": 4, \"batches_seen\": 1720, \"train_examples_seen\": 17196, \"loss\": 0.03449869817122817}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 67.0, \"ner_token_f1\": 78.0435}, \"time_spent\": \"1:37:41\", \"epochs_done\": 4, \"batches_seen\": 1720, \"train_examples_seen\": 17196, \"impatience\": 86, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [02:00,  3.18s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.02it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 57.1429, \"ner_token_f1\": 78.4314}, \"time_spent\": \"1:38:51\", \"epochs_done\": 4, \"batches_seen\": 1740, \"train_examples_seen\": 17396, \"loss\": 0.033580774208530784}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 59.9899, \"ner_token_f1\": 60.4230}, \"time_spent\": \"1:38:51\", \"epochs_done\": 4, \"batches_seen\": 1740, \"train_examples_seen\": 17396, \"impatience\": 87, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "55it [03:08,  3.54s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 66.6667, \"ner_token_f1\": 85.0}, \"time_spent\": \"1:39:58\", \"epochs_done\": 4, \"batches_seen\": 1760, \"train_examples_seen\": 17596, \"loss\": 0.04597923029214144}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 11.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 67.0, \"ner_token_f1\": 81.0}, \"time_spent\": \"1:39:58\", \"epochs_done\": 4, \"batches_seen\": 1760, \"train_examples_seen\": 17596, \"impatience\": 88, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "75it [04:16,  3.43s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.94it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 66.6667, \"ner_token_f1\": 83.871}, \"time_spent\": \"1:41:06\", \"epochs_done\": 4, \"batches_seen\": 1780, \"train_examples_seen\": 17796, \"loss\": 0.04262169022113085}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 64.0523, \"ner_token_f1\": 71.0020}, \"time_spent\": \"1:41:06\", \"epochs_done\": 4, \"batches_seen\": 1780, \"train_examples_seen\": 17796, \"impatience\": 89, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "95it [05:26,  3.93s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 56.0, \"ner_token_f1\": 83.0769}, \"time_spent\": \"1:42:18\", \"epochs_done\": 4, \"batches_seen\": 1800, \"train_examples_seen\": 17996, \"loss\": 0.03246208317577839}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 68.0100, \"ner_token_f1\": 75.4354}, \"time_spent\": \"1:42:18\", \"epochs_done\": 4, \"batches_seen\": 1800, \"train_examples_seen\": 17996, \"impatience\": 90, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "115it [06:34,  3.24s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 55.0, \"ner_token_f1\": 60.0}, \"time_spent\": \"1:43:26\", \"epochs_done\": 4, \"batches_seen\": 1820, \"train_examples_seen\": 18196, \"loss\": 0.03388067369814962}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 71.1288, \"ner_token_f1\": 80.4000}, \"time_spent\": \"1:43:26\", \"epochs_done\": 4, \"batches_seen\": 1820, \"train_examples_seen\": 18196, \"impatience\": 91, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "135it [07:50,  3.69s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:01,  1.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 64.5455, \"ner_token_f1\": 89.4737}, \"time_spent\": \"1:44:41\", \"epochs_done\": 4, \"batches_seen\": 1840, \"train_examples_seen\": 18396, \"loss\": 0.03266799869015813}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 72.12, \"ner_token_f1\": 74.0}, \"time_spent\": \"1:44:41\", \"epochs_done\": 4, \"batches_seen\": 1840, \"train_examples_seen\": 18396, \"impatience\": 92, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "155it [08:57,  3.36s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.28it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 73.6842, \"ner_token_f1\": 93.3333}, \"time_spent\": \"1:45:47\", \"epochs_done\": 4, \"batches_seen\": 1860, \"train_examples_seen\": 18596, \"loss\": 0.03930192028637976}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 10.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 65.3470, \"ner_token_f1\": 83.0}, \"time_spent\": \"1:45:47\", \"epochs_done\": 4, \"batches_seen\": 1860, \"train_examples_seen\": 18596, \"impatience\": 93, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "175it [10:01,  3.10s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.42it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 94.7368, \"ner_token_f1\": 98.9247}, \"time_spent\": \"1:46:52\", \"epochs_done\": 4, \"batches_seen\": 1880, \"train_examples_seen\": 18796, \"loss\": 0.03815575576154515}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 14.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 67.0468, \"ner_token_f1\": 89.01}, \"time_spent\": \"1:46:52\", \"epochs_done\": 4, \"batches_seen\": 1880, \"train_examples_seen\": 18796, \"impatience\": 94, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "195it [11:09,  3.29s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  2.00it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 100.0, \"ner_token_f1\": 100.0}, \"time_spent\": \"1:48:00\", \"epochs_done\": 4, \"batches_seen\": 1900, \"train_examples_seen\": 18996, \"loss\": 0.037056953040882946}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 76.0, \"ner_token_f1\": 62.1999}, \"time_spent\": \"1:48:00\", \"epochs_done\": 4, \"batches_seen\": 1900, \"train_examples_seen\": 18996, \"impatience\": 95, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "215it [12:14,  3.05s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.26it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 93.3333, \"ner_token_f1\": 97.1429}, \"time_spent\": \"1:49:05\", \"epochs_done\": 4, \"batches_seen\": 1920, \"train_examples_seen\": 19196, \"loss\": 0.032412983584799805}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 78.7400, \"ner_token_f1\": 64.01488}, \"time_spent\": \"1:49:05\", \"epochs_done\": 4, \"batches_seen\": 1920, \"train_examples_seen\": 19196, \"impatience\": 96, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [13:23,  3.08s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.73it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 63.3333, \"ner_token_f1\": 74.0741}, \"time_spent\": \"1:50:13\", \"epochs_done\": 4, \"batches_seen\": 1940, \"train_examples_seen\": 19396, \"loss\": 0.04083025252912194}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 72.0400, \"ner_token_f1\": 68.0}, \"time_spent\": \"1:50:13\", \"epochs_done\": 4, \"batches_seen\": 1940, \"train_examples_seen\": 19396, \"impatience\": 97, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "255it [14:26,  3.16s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.39it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 75.2941, \"ner_token_f1\": 88.0100}, \"time_spent\": \"1:51:16\", \"epochs_done\": 4, \"batches_seen\": 1960, \"train_examples_seen\": 19596, \"loss\": 0.03786541009321809}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 78.0400, \"ner_token_f1\": 75.8484}, \"time_spent\": \"1:51:16\", \"epochs_done\": 4, \"batches_seen\": 1960, \"train_examples_seen\": 19596, \"impatience\": 98, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "275it [15:31,  3.54s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 76.9231, \"ner_token_f1\": 92.3077}, \"time_spent\": \"1:52:20\", \"epochs_done\": 4, \"batches_seen\": 1980, \"train_examples_seen\": 19796, \"loss\": 0.0275567369768396}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 82.0177, \"ner_token_f1\": 90.4077}, \"time_spent\": \"1:52:21\", \"epochs_done\": 4, \"batches_seen\": 1980, \"train_examples_seen\": 19796, \"impatience\": 99, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "295it [16:37,  3.13s/it]\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  1.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"train\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 77.0588, \"ner_token_f1\": 80.0}, \"time_spent\": \"1:53:29\", \"epochs_done\": 4, \"batches_seen\": 2000, \"train_examples_seen\": 19996, \"loss\": 0.03778940388583578}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1it [00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 84.0177, \"ner_token_f1\": 90.4077}, \"time_spent\": \"1:53:29\", \"epochs_done\": 4, \"batches_seen\": 2000, \"train_examples_seen\": 19996, \"impatience\": 100, \"patience_limit\": 100}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-25 04:02:16.613 INFO in 'deeppavlov.core.trainers.nn_trainer'['nn_trainer'] at line 305: Ran out of patience\n",
      "295it [16:43,  3.40s/it]\n",
      "2022-12-25 04:02:22.956 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 112: [loading vocabulary from C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\tag.dict]\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2022-12-25 04:02:25.317 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 153: Load path C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\model is given.\n",
      "2022-12-25 04:02:25.333 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 160: Load path C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\model.pth.tar exists.\n",
      "2022-12-25 04:02:25.333 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 161: Initializing `TorchTransformersSequenceTagger` from saved.\n",
      "2022-12-25 04:02:25.333 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 168: Loading weights from C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\model.pth.tar.\n",
      "2022-12-25 04:02:26.411 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 102: Model was successfully initialized! Model summary:\n",
      " BertForTokenClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=37, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 12.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"valid\": {\"eval_examples_count\": 10, \"metrics\": {\"ner_f1\": 84.0177, \"ner_token_f1\": 90.4077}, \"time_spent\": \"0:00:01\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-12-25 04:02:32.597 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 112: [loading vocabulary from C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\tag.dict]\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2022-12-25 04:02:34.909 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 153: Load path C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\model is given.\n",
      "2022-12-25 04:02:34.909 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 160: Load path C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\model.pth.tar exists.\n",
      "2022-12-25 04:02:34.909 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 161: Initializing `TorchTransformersSequenceTagger` from saved.\n",
      "2022-12-25 04:02:34.909 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 168: Loading weights from C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\model.pth.tar.\n",
      "2022-12-25 04:02:35.964 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 102: Model was successfully initialized! Model summary:\n",
      " BertForTokenClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=37, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-25 04:02:35.968 INFO in 'deeppavlov.core.models.torch_model'['torch_model'] at line 210: Saving model to C:\\Users\\Андрей\\.deeppavlov\\models\\ner_ontonotes_torch_bert_mult_crf\\model.pth.tar.\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov import train_model\n",
    "from deeppavlov.core.commands.utils import parse_config\n",
    "\n",
    "model_config = parse_config('ner_ontonotes_bert_mult')\n",
    "\n",
    "model_config['dataset_reader']['data_path'] = '.deeppavlov/ttv'\n",
    "model_config['metadata']['variables']['NER_PATH'] = '.deeppavlov/savemodel'\n",
    "\n",
    "model_config = train_model(model_config, download=True)\n",
    "model_config.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90ee669f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Кодил', 'в', 'универе', 'на', 'джаве', '.', 'Хотел', 'бы', 'стать', 'бэкенд', 'программистом', '.']],\n",
       " [['B-PASTNORMAL', 'O', 'O', 'O', 'Java', 'O', 'O', 'O', 'O', 'Backend', 'O', 'O']]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config([\"Кодил в универе на джаве. Хотел бы стать бэкенд программистом.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "177a55ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Писал', 'код', 'на', 'питон', '.', 'Знаю', 'Java', '.']],\n",
       " [['B-PASTNORMAL', 'I-PASTNORMAL', 'O', 'PY', 'O', 'B-PRESENTNORMAL', 'Java', 'O']]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config([\"Писал код на питон. Знаю Java.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50a5791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
